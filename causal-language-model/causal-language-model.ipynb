{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1cfa874-83f5-467f-b3c7-a38ea9878ce6",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "Original Notebook [here](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145fa426-1eca-4e7a-b5a8-3472e56fd3eb",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14f59c1e-d893-4470-822f-3284a5ea5feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36.1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, pipeline, set_seed\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b78d89-c780-4664-801c-b60ff031ecfc",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "427e1fea-4b6a-4e68-848f-e16de73b51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use  Wikitext 2 dataset\n",
    "\n",
    "full_datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c184910e-c06e-44c5-8e76-f74b307cfe2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea70bd26-a16c-42fe-9d69-3e67d65f71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsize dataset because I am on a CPU!\n",
    "num_train = 400\n",
    "num_test = 100\n",
    "num_validation = 100\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    \"train\": Dataset.from_dict({\n",
    "            \"text\": full_datasets[\"train\"][\"text\"][0:num_train]\n",
    "        }),\n",
    "    \"test\": Dataset.from_dict({\n",
    "            \"text\": full_datasets[\"test\"][\"text\"][0:num_test]\n",
    "        }),\n",
    "    \"validation\": Dataset.from_dict({\n",
    "            \"text\": full_datasets[\"validation\"][\"text\"][0:num_validation]\n",
    "        })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1804038d-7dd3-47a6-b041-cf479ae2d934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15a708-13d4-49e6-89f1-ed947d8cd730",
   "metadata": {},
   "source": [
    "# Causal language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "758f9006-0c20-4c67-a1e3-e8c31cd135a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a946f-2196-48ee-b31b-651b5026b46f",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "829f46ed-9654-4454-8edc-a2ad3f0471c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69e4ac82-4bf1-4587-a8db-2db6eca25d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e59f264e-a864-470d-be90-2638714cc871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0badf9d50cd5421d8218c8ab914b5dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f483166f53d4d8e9ff0392e3f6de949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39c571af2ff4defb880bcf8d16c8fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91083f3f-0ade-4efa-956a-f3fcb4abf5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [796, 569, 18354, 7496, 17740, 6711, 796, 220, 198],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8953c69a-8654-457a-b9c5-0239da95f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may be a little too much for the GPU memory so we take a reasonable block size\n",
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75fc7ebd-8a79-43ba-b5fd-a8d67305f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bfc4a0c-4a77-48ab-bdfa-9b31bc9a4de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537275869ab44c6ba49975f6a10e6619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447c025fa8074ea98568bb49ccecc605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf6602f498d4e0eaabcf87142f969e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0849b88e-2ea8-4ad3-8f6f-78bcd36aa383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 147\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 47\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d4186a1-52e0-451a-b5ec-c5a8d12d6530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' game and follows the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \". \\n The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries, along with Valkyria Chronicles II director Takeshi Oz'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e95bd-79b7-4cad-91d4-bab6c6baf668",
   "metadata": {},
   "source": [
    "## Explanation of group text function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7008e-37c3-4cd3-988a-5de5254d0de6",
   "metadata": {},
   "source": [
    "```Python\n",
    "examples = {\n",
    "    \"input_ids\": [\n",
    "        [101, 2054, 2003, 1037, 2158, 1012, 15, 102],\n",
    "        [101, 1045, 2064, 2022, 1037, 2158, 1012, 102],\n",
    "        # ... other input_ids lists\n",
    "    ],\n",
    "    \"attention_mask\": [\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        # ... other attention_mask lists\n",
    "    ],\n",
    "    # ... other keys in examples\n",
    "}\n",
    "\n",
    "block_size = 4\n",
    "\n",
    "concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "\n",
    "# total_length = 16\n",
    "\n",
    "result = {\n",
    "    k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "# result = {'input_ids': [[101, 2054, 2003, 1037],\n",
    "#  [2158, 1012, 15, 102],\n",
    "#  [101, 1045, 2064, 2022],\n",
    "#  [1037, 2158, 1012, 102]],\n",
    "# 'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed77207-b979-4861-8eeb-c2e58cdc00e6",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e7703a7-bb43-45fc-8f8e-a6118f0ff814",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f95f3ae7-cde1-4d6c-9436-695d060ce693",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9249c05-8d8c-4c26-b8ce-8bfd60b3e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abeea7eb-3b41-4bc7-a1f1-3001399a1ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [190/190 25:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.165716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.092966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.051461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.026987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.013767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.009618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.005503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.003449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.003416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.004277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18cbbba8-080f-4b82-8ef7-dd05bd0989c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=190, training_loss=3.708026765522204, metrics={'train_runtime': 1533.8826, 'train_samples_per_second': 0.958, 'train_steps_per_second': 0.124, 'total_flos': 48013277921280.0, 'train_loss': 3.708026765522204, 'epoch': 10.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b675a97-3f19-41be-9349-fcb61a8b5ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 54.83\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03688e2b-1540-4dbf-93e2-2b47c19f522d",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de6ab24b-48c3-4e39-8542-90e8f42877a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_name = \"./distilgpt2-tutorial-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13648e07-1206-4c2b-ad01-d6381228b83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./distilgpt2-tutorial-model/tokenizer_config.json',\n",
       " './distilgpt2-tutorial-model/special_tokens_map.json',\n",
       " './distilgpt2-tutorial-model/vocab.json',\n",
       " './distilgpt2-tutorial-model/merges.txt',\n",
       " './distilgpt2-tutorial-model/added_tokens.json',\n",
       " './distilgpt2-tutorial-model/tokenizer.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(custom_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b55a701e-3bc4-4df6-b321-51a8ee00614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(custom_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29b18e10-7bff-44b7-908e-18e2c1bfa98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"./distilgpt2-test-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c182d8b7-3561-4b50-b392-46998ab33faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Character designer Raita Honjou and composer Hitoshi Sakimoto, in the design for the video game, published the video game adaptation of Resident Evil Revelations in September 2014.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'},\n",
       " {'generated_text': 'Character designer Raita Honjou and composer Hitoshi Sakimoto, who contributed the sound design, announced the final designs for the film on Friday (Jan. 18). \"We had only very limited budget and could only confirm that, due to difficulties in planning, production direction, and the budget on the film we had not achieved it,\" said Honjou, the studio president and director of the film production team. \"We had been doing all this for a while when we were not confident.\" Honjou said the film is likely to feature an action-packed ending, one that emphasizes human nature. Honjou added that the movie \"is about a family that always has its problems. As to why it needs such a sequel, it seems the main reason why a sequel is needed,\" he adds. \"It seems like a good plan. The film will be a good movie.\" Honjou said the films have been planned for three months and have been delayed until December 2019.'},\n",
       " {'generated_text': 'Character designer Raita Honjou and composer Hitoshi Sakimoto, as well as musicians Shouhei Fujii (a member of Takamori and Daft Punk), as well as actors Takumi Yamada (lead vocalist of Attack on Titan), Katsuda Sakamoto, Tomohiro Uchikawa, Yoshisuke Takahashi, Shinichi Nagata, and Takumaki Takagi.\\n\\n\\nThe full statement of the opening theme for the Persona 5 live event will be broadcast on Friday 11 March in Tsubato. You can watch the live broadcast online through the game\\u200ds website and via the dedicated website. All rights reserved.\\n\\nSource: Persona 5 Online\\n[Via Satoru News][Twitter]'},\n",
       " {'generated_text': 'Character designer Raita Honjou and composer Hitoshi Sakimoto, co-in-development of Masamune.\\n\\n\\nImage credit: Yousuke Hachima | Source\\nComments\\ncomments'},\n",
       " {'generated_text': \"Character designer Raita Honjou and composer Hitoshi Sakimoto, among others, will be joined at the Japan Toy Show in Japan by composer Hioshi Sawamura, as well as music video game creator Kino Kobayashi, executive producer and lead guitarist of the upcoming series.\\n\\n\\n\\n\\nThe series is slated to be made available exclusively on Crunchyroll's website.\\nSee a recap of the series below.\"},\n",
       " {'generated_text': 'Character designer Raita Honjou and composer Hitoshi Sakimoto, also known for their contributions to the film. The music was designed by the Japanese artist Haruka Noguchi.\\n\\nAn interview with The New York Times revealed that in order to play the game (in the current game), the player must play through an array of rules; each requires a special card, and after each card has been played you must choose which card to play:\\nThis card will not give you the benefit of a special card and only will play during the entire rest of the game. You have to choose a new card, because a special card will not work but you will lose a special card. You will need to choose a new card. You are never allowed to move any more than you are allowed to move if the card is removed without paying your entire amount. When you have completed the game and your favorite game card is unlocked, you cannot move any more than you normally can.\\nThe'},\n",
       " {'generated_text': \"Character designer Raita Honjou and composer Hitoshi Sakimoto, also present the animation in the video:\\n“I hope to give the animation the proper visual representation and focus for all of you. It“ was an important project that I have been working on for so long. I\\u202a am happy to announce that the video has been released and is going home for the first time. I am excited to share this with you,“ I would like to thank my friends like a complete team of designers and animators. This video, featuring Raita Honjou and Hitoshi Sakimoto, will be a must to watch. You may still be able to browse the gallery or read the video's notes here and we hope you all enjoy the amazing animation.\"}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(10)\n",
    "generator(\"Character designer Raita Honjou and composer Hitoshi Sakimoto,\", max_length=200, num_return_sequences=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5d201-8fbf-4d46-9c15-cea27c089e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
